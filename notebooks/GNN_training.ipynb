{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c83d186",
   "metadata": {},
   "source": [
    "# GNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925f3af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:13.180199Z",
     "start_time": "2025-06-30T19:06:10.472825Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "from gnn_model.HeteroGAT import HeteroGAT\n",
    "from gnn_model.Trainer import Trainer\n",
    "from data_processing.data_loader import DataLoader\n",
    "from data_processing.config import DataProcessingConfig\n",
    "from utils import visualize_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffaa6883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:13.255158Z",
     "start_time": "2025-06-30T19:06:13.253251Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.serialization\n",
    "from torch_geometric.data.storage import BaseStorage\n",
    "\n",
    "# Add BaseStorage class to safe globals for loading\n",
    "torch.serialization.add_safe_globals([BaseStorage])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc1902",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3592688e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:13.266375Z",
     "start_time": "2025-06-30T19:06:13.263950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scenarios\n",
    "case_study = 'manhattan_case_study'\n",
    "# case_study = 'GNN_study'\n",
    "results_dir = os.path.join('..', 'studies', case_study, 'results')\n",
    "scenario_names = [\n",
    "    # 'test_small_1',\n",
    "    # 'test_small_1',\n",
    "    # 'test_small_1',\n",
    "    'test_manhattan_scenario_1',\n",
    "    # 'test_manhattan_scenario_1',\n",
    "    # 'test_manhattan_scenario_1',\n",
    "    'test_manhattan_scenario_2',\n",
    "    'test_manhattan_scenario_3',\n",
    "    # # 'test_manhattan_scenario_4',\n",
    "    # # 'test_manhattan_scenario_5',\n",
    "    # # 'test_manhattan_scenario_6', \n",
    "    # # 'test_manhattan_scenario_7', \n",
    "    # # 'test_manhattan_scenario_8',\n",
    "    # # 'test_manhattan_scenario_9', \n",
    "    # # 'test_manhattan_scenario_10',\n",
    "    # # 'test_manhattan_scenario_11', \n",
    "    # # 'test_manhattan_scenario_12',\n",
    "]\n",
    "                  \n",
    "scenarios = [os.path.join(results_dir, sc) for sc in scenario_names]\n",
    "\n",
    "# Create config\n",
    "config = DataProcessingConfig(\n",
    "    # sim_duration=1800,\n",
    ")\n",
    "\n",
    "# Set to True only when data needs to be reprocessed\n",
    "overwrite = False\n",
    "# Set to True to balance edges in the graph\n",
    "balance_edges = False\n",
    "edge_balance_ratio = 1.0  # Ratio of positive to negative edges\n",
    "\n",
    "pos_weight = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcca3977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:26.300537Z",
     "start_time": "2025-06-30T19:06:13.271754Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading scenarios: 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario split: Train=1, Val=1, Test=1 scenarios\n",
      "Timestep split: Train=1439, Val=1440, Test=1440 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Safe data loading with error handling\n",
    "def load_data_safely():\n",
    "    gc.collect()  # Clean up memory before loading\n",
    "    torch.cuda.empty_cache()  # Clear GPU cache if available\n",
    "    \n",
    "    loader = DataLoader(scenarios, config, overwrite=overwrite, balance_edges=balance_edges, edge_balance_ratio=edge_balance_ratio)\n",
    "    data, *masks = loader.load_data()\n",
    "    \n",
    "    # Validate loaded data\n",
    "    if not data or len(data) == 0:\n",
    "        raise ValueError(\"No data was loaded\")\n",
    "        \n",
    "    return data, masks\n",
    "    \n",
    "data, masks = load_data_safely()\n",
    "train_masks, val_masks, test_masks = masks if masks else (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534f682f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:26.314910Z",
     "start_time": "2025-06-30T19:06:26.311438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 4319 data points\n",
      "Train/Val/Test split: 1439/1440/1440\n"
     ]
    }
   ],
   "source": [
    "# Validate loaded data\n",
    "if data is not None:\n",
    "    print(f\"Successfully loaded {len(data)} data points\")\n",
    "    print(f\"Train/Val/Test split: {sum(train_masks)}/{sum(val_masks)}/{sum(test_masks)}\")\n",
    "else:\n",
    "    print(\"Failed to load data. Please check the error message above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a82309",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82047224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:26.331191Z",
     "start_time": "2025-06-30T19:06:26.328341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "num_classes = 1  # Binary classification - single output logit with sigmoid activation\n",
    "hidden_channels = 128  # Size of hidden layers in GNN\n",
    "epochs = 200  # Maximum number of training epochs (may stop earlier due to early stopping)\n",
    "batch_size = 16  # Number of graphs per batch\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6ff48",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7435a7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:26.386142Z",
     "start_time": "2025-06-30T19:06:26.344811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 128 hidden channels and 1 output channel\n"
     ]
    }
   ],
   "source": [
    "# Initialize model with error handling\n",
    "model = HeteroGAT(hidden_channels, num_classes).to(device=device)\n",
    "print(f\"Model initialized with {hidden_channels} hidden channels and {num_classes} output channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294010f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:26.394255Z",
     "start_time": "2025-06-30T19:06:26.390685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 1 empty graphs from dataset\n",
      "\n",
      "================================================================================\n",
      "Training Configuration\n",
      "--------------------------------------------------------------------------------\n",
      "Batch Size:          16\n",
      "Max Epochs:          200\n",
      "Device:              cpu\n",
      "Pos Weight:          1.0000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training setup with weighted BCE loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "trainer = Trainer(data, device, masks, config, batch_size=batch_size, epochs=epochs, pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0fb3e42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:26.409744Z",
     "start_time": "2025-06-30T19:06:26.407947Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Training with progress tracking and error handling\n",
    "# try:\n",
    "#     # Add numpy scalar to safe globals before training\n",
    "#     import torch.serialization\n",
    "#     torch.serialization.add_safe_globals(['numpy._core.multiarray.scalar'])\n",
    "    \n",
    "#     # Start training\n",
    "#     trainer.train(model, optimizer)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during training: {str(e)}\")\n",
    "#     # Print more detailed error information\n",
    "#     import traceback\n",
    "#     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9534e",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95ccf36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:29.107605Z",
     "start_time": "2025-06-30T19:06:26.418424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9954856318387989\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(scenarios, config)\n",
    "(X_train_vr, y_train_vr), (X_val_vr, y_val_vr), (X_test_vr, y_test_vr) = loader.get_edge_classification_data_for_rf(edge_type='vr_graph')\n",
    "\n",
    "# Now you can use X_train, y_train with scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_vr = RandomForestClassifier()\n",
    "clf_vr.fit(X_train_vr, y_train_vr)\n",
    "print(\"Validation accuracy:\", clf_vr.score(X_val_vr, y_val_vr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06700668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Accuracy: 0.9983148114292193\n",
      "Precision: 0.9802828151347514\n",
      "Recall: 0.9279333520022403\n",
      "F1 Score: 0.9533900133787925\n",
      "ROC AUC: 0.991741851883105\n",
      "Confusion Matrix:\n",
      " [[3772514    1333]\n",
      " [   5147   66273]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3773847\n",
      "           1       0.98      0.93      0.95     71420\n",
      "\n",
      "    accuracy                           1.00   3845267\n",
      "   macro avg       0.99      0.96      0.98   3845267\n",
      "weighted avg       1.00      1.00      1.00   3845267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_vr = clf_vr.predict(X_val_vr)\n",
    "y_val_proba_vr = clf_vr.predict_proba(X_val_vr)[:, 1] if hasattr(clf_vr, \"predict_proba\") else None\n",
    "\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_vr, y_val_pred_vr))\n",
    "print(\"Precision:\", precision_score(y_val_vr, y_val_pred_vr, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_val_vr, y_val_pred_vr, zero_division=0))\n",
    "print(\"F1 Score:\", f1_score(y_val_vr, y_val_pred_vr, zero_division=0))\n",
    "if y_val_proba_vr is not None:\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_val_vr, y_val_proba_vr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_vr, y_val_pred_vr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_vr, y_val_pred_vr, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b464f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_val_proba_vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21eb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.data_loader import DataLoader\n",
    "\n",
    "loader = DataLoader(scenarios, config)\n",
    "(X_train_rr, y_train_rr), (X_val_rr, y_val_rr), (X_test_rr, y_test_rr) = loader.get_edge_classification_data_for_rf(edge_type='rr_graph')\n",
    "\n",
    "clf_rr = RandomForestClassifier()\n",
    "clf_rr.fit(X_train_rr, y_train_rr)\n",
    "print(\"Validation accuracy:\", clf_rr.score(X_val_rr, y_val_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_rr = clf_rr.predict(X_val_rr)\n",
    "y_val_proba_rr = clf_rr.predict_proba(X_val_rr)[:, 1] if hasattr(clf_rr, \"predict_proba\") else None\n",
    "\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_rr, y_val_pred_rr))\n",
    "print(\"Precision:\", precision_score(y_val_rr, y_val_pred_rr, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_val_rr, y_val_pred_rr, zero_division=0))\n",
    "print(\"F1 Score:\", f1_score(y_val_rr, y_val_pred_rr, zero_division=0))\n",
    "if y_val_proba_rr is not None:\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_val_rr, y_val_proba_rr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_rr, y_val_pred_rr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_rr, y_val_pred_rr, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acce1cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3773847\n",
      "           1       0.96      0.91      0.94     71420\n",
      "\n",
      "    accuracy                           1.00   3845267\n",
      "   macro avg       0.98      0.96      0.97   3845267\n",
      "weighted avg       1.00      1.00      1.00   3845267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_vr = XGBClassifier()\n",
    "xgb_vr.fit(X_train_vr, y_train_vr)\n",
    "\n",
    "y_pred_vr = xgb_vr.predict(X_val_vr)\n",
    "\n",
    "print(classification_report(y_val_vr, y_pred_vr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5f0049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Training set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3740710\n",
      "           1       0.97      0.92      0.94     72266\n",
      "\n",
      "    accuracy                           1.00   3812976\n",
      "   macro avg       0.99      0.96      0.97   3812976\n",
      "weighted avg       1.00      1.00      1.00   3812976\n",
      "\n",
      "XGBoost - Validation set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3773847\n",
      "           1       0.96      0.91      0.94     71420\n",
      "\n",
      "    accuracy                           1.00   3845267\n",
      "   macro avg       0.98      0.96      0.97   3845267\n",
      "weighted avg       1.00      1.00      1.00   3845267\n",
      "\n",
      "XGBoost - Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3830959\n",
      "           1       0.98      0.83      0.90     70923\n",
      "\n",
      "    accuracy                           1.00   3901882\n",
      "   macro avg       0.99      0.91      0.95   3901882\n",
      "weighted avg       1.00      1.00      1.00   3901882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost predictions on train, val, and test sets, similar to Random Forest\n",
    "# Training set\n",
    "y_train_pred_xgb_vr = xgb_vr.predict(X_train_vr)\n",
    "print(\"XGBoost - Training set classification report:\")\n",
    "print(classification_report(y_train_vr, y_train_pred_xgb_vr))\n",
    "\n",
    "# Validation set\n",
    "y_val_pred_xgb_vr = xgb_vr.predict(X_val_vr)\n",
    "print(\"XGBoost - Validation set classification report:\")\n",
    "print(classification_report(y_val_vr, y_val_pred_xgb_vr))\n",
    "\n",
    "# Test set\n",
    "y_test_pred_xgb_vr = xgb_vr.predict(X_test_vr)\n",
    "print(\"XGBoost - Test set classification report:\")\n",
    "print(classification_report(y_test_vr, y_test_pred_xgb_vr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_rr = XGBClassifier()\n",
    "xgb_rr.fit(X_train_rr, y_train_rr)\n",
    "\n",
    "y_pred_rr = xgb_rr.predict(X_val_rr)\n",
    "\n",
    "print(classification_report(y_val_rr, y_pred_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost predictions on train, val, and test sets, similar to Random Forest\n",
    "# Training set\n",
    "y_train_pred_xgb_rr = xgb_rr.predict(X_train_rr)\n",
    "print(\"XGBoost - Training set classification report:\")\n",
    "print(classification_report(y_train_rr, y_train_pred_xgb_rr))\n",
    "\n",
    "# Validation set\n",
    "y_val_pred_xgb_rr = xgb_rr.predict(X_val_rr)\n",
    "print(\"XGBoost - Validation set classification report:\")\n",
    "print(classification_report(y_val_rr, y_val_pred_xgb_rr))\n",
    "\n",
    "# Test set\n",
    "y_test_pred_xgb_rr = xgb_rr.predict(X_test_rr)\n",
    "print(\"XGBoost - Test set classification report:\")\n",
    "print(classification_report(y_test_rr, y_test_pred_xgb_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0e765",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's visualize a sample graph from our dataset and analyze model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d029720",
   "metadata": {},
   "source": [
    "### Graph Visualization Functions\n",
    "\n",
    "The following cells implement visualization functionality for our heterogeneous graph neural network:\n",
    "\n",
    "1. Node visualization:\n",
    "   - Vehicles: red nodes\n",
    "   - Requests: turquoise nodes\n",
    "\n",
    "2. Edge visualization:\n",
    "   - True assignments: solid red lines\n",
    "   - Non-assignments: dotted gray lines\n",
    "   - Predicted assignments: semi-transparent blue lines (with probability scores)\n",
    "\n",
    "3. Additional features:\n",
    "   - Node labels (V for vehicles, R for requests)\n",
    "   - Edge probability labels for predicted assignments\n",
    "   - Comprehensive legend\n",
    "   - Force-directed layout for clear visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d4ae7ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:06:29.112496Z",
     "start_time": "2025-06-30T12:37:09.646226Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize_graph(data, graph_idx=0, model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e4721c62b5891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FleetPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
